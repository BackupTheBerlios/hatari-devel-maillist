<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [hatari-devel] Ym / Dma mixing
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/hatari-devel/2009q1/index.html" >
   <LINK REL="made" HREF="mailto:hatari-devel%40lists.berlios.de?Subject=Re%3A%20%5Bhatari-devel%5D%20Ym%20/%20Dma%20mixing&In-Reply-To=%3CPine.LNX.4.64.0902071340310.22798%40localhost%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000126.html">
   <LINK REL="Next"  HREF="000134.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[hatari-devel] Ym / Dma mixing</H1>
    <B>npomarede at corp.free.fr</B> 
    <A HREF="mailto:hatari-devel%40lists.berlios.de?Subject=Re%3A%20%5Bhatari-devel%5D%20Ym%20/%20Dma%20mixing&In-Reply-To=%3CPine.LNX.4.64.0902071340310.22798%40localhost%3E"
       TITLE="[hatari-devel] Ym / Dma mixing">npomarede at corp.free.fr
       </A><BR>
    <I>Sat Feb  7 14:00:56 CET 2009</I>
    <P><UL>
        <LI>Previous message: <A HREF="000126.html">[hatari-devel] Ym / Dma mixing
</A></li>
        <LI>Next message: <A HREF="000134.html">[hatari-devel] Ym / Dma mixing
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#128">[ date ]</a>
              <a href="thread.html#128">[ thread ]</a>
              <a href="subject.html#128">[ subject ]</a>
              <a href="author.html#128">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>On Sat, 7 Feb 2009, Jean-Baptiste Berlioz wrote:

&gt;<i> Hello,
</I>&gt;<i>
</I>&gt;&gt;&gt;&gt;&gt;<i> + No more desync between SDL buffer and mixing buffer (no more
</I>&gt;&gt;&gt;&gt;&gt;<i> mixing buffer btw)
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> What do you mean by that? Was there a problem?
</I>&gt;&gt;<i>
</I>&gt;<i>
</I>&gt;<i> Yes, the old SDL audio callback was dealing with the case.
</I>&gt;<i> If there was not enough samples in the buffer, then it was trying to
</I>&gt;<i> compensate with different methods, see below.
</I>&gt;<i>
</I>&gt;<i> &gt;&gt;&gt;&gt; - Now, when a ym register is written, the affected sample number
</I>&gt;<i> &gt;&gt;&gt;&gt; is computed and the change is stored in a list.
</I>&gt;<i> &gt;&gt;&gt;&gt; When the SDL audio callback needs samples, it calls the ym
</I>&gt;<i> &gt;&gt;&gt;&gt; emulation, and the ym emulation replay the history and generate
</I>&gt;<i> &gt;&gt;&gt;&gt; the samples.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; So where's the advantage to the old way of generating the samples
</I>&gt;<i> &gt; directly?
</I>&gt;<i>
</I>&gt;<i> The old method was generating samples when a register was changed. So
</I>&gt;<i> between two registers change, no samples where generated. The workaround
</I>&gt;<i> was to generate samples at each VBL, but the ST VBL and the SDL callback
</I>&gt;<i> are not synchronized (and can't be afaik).
</I>&gt;<i>
</I>&gt;<i> The new method can generate samples from the last register set.
</I>
with the current method, you always have 1/50 sec of sound buffer ready to 
be played (without discontinuity between each buffer), so I don't see 
where's the problem ?

In the end, we need to have 44100/50 samples for one vbl to have 
continuous sound, so I don't see why it's not ok to generate those sample 
in one go, instead of generating them on the fly as you suggest ? Both 
method will provide the same values for the 44100/50 samples, so why 
complexifying it with an history ?

As long as we can feed the sdl callback with some 44.1 kHz sound for 
example, the current method works just fine and no one has reported 
problem at this level so far, it doesn't matter whether the buffer was 
completly built in advance or generated on the fly.

We just need to ensure the routines are fast enough to substain a 44.1 kHz 
rate (and in that case, I think generating samples on the fly by replaying 
an history that needs to be stored/managed will indeed require more cpu 
than before).


&gt;<i>
</I>&gt;&gt;&gt;&gt;&gt;<i> + The SDL audio buffer size is frequency dependant (and small).
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> I don't think that this is a good idea to use sizes smaller than 512...
</I>&gt;&gt;<i> according to the SDL documentation:
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> &quot; desired-&gt;samples : The desired size of the audio buffer in samples.
</I>&gt;&gt;<i> This number should be a power of two, and may be adjusted by the audio
</I>&gt;&gt;<i> driver to a value more suitable for the hardware. Good values seem to
</I>&gt;&gt;<i> range between 512 and 8192 inclusive, depending on the application and
</I>&gt;&gt;<i> CPU speed. Smaller values yield faster response time, but can lead to
</I>&gt;&gt;<i> underflow if the application is doing heavy processing and cannot fill
</I>&gt;&gt;<i> the audio buffer in time. &quot;
</I>&gt;<i>
</I>&gt;<i> Ok, But it should be kept as small as possible, or the sound will be
</I>&gt;<i> late, i'll change it to 512.
</I>&gt;<i> Also note that if you set the same buffer size for all frequencies, the
</I>&gt;<i> sound will be more or less late depending on the output frequency.
</I>
As thomas said, some old sound cards have some really bad alsa 
implementation under linux, and using too small buffer can cause some 
problems.
At 16 bits stereo 44.1 kHz, with a refresh rate of 50 Hz, we need 3528 
bytes to play one vbl of sound, so even if we use an sdl buffer size of 
7000 bytes, this means we would just have the equivalent latency of 1 VBL, 
which is really hardly noticeable (especially if you consider that the 
resulting video is already delayed 1 or 2 VBL today, due to converting the 
ST screen, copying it to sdl buffer, having sdl displays it).


&gt;&gt;&gt;&gt;&gt;<i> + Added some 4 pole filters (configurable).
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> What are they good for? There is hardly any comment in your patch about
</I>&gt;&gt;<i> them.
</I>&gt;<i>
</I>&gt;<i> The code can handle low-pass and high-pass filters.
</I>&gt;<i>
</I>&gt;<i> The Dma sounds generated by the STE are sent to the LMC via a 4 pole filter.
</I>&gt;<i>
</I>&gt;<i> Also, when resampling audio, it's good to remove wrong frequencies
</I>&gt;<i> introduced by the proccess with a low-pass filter. (when downsampling
</I>&gt;<i> it's might be good to remove frequencies that can't be handled by the
</I>&gt;<i> new samplerate before resampling).
</I>
Filters should be optionnal anyway, they can remove bad frequencies, but 
they can also soften the sound too much and remove some well known &quot;buzz&quot; 
effects used in the ym for example.



Nicolas

</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000126.html">[hatari-devel] Ym / Dma mixing
</A></li>
	<LI>Next message: <A HREF="000134.html">[hatari-devel] Ym / Dma mixing
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#128">[ date ]</a>
              <a href="thread.html#128">[ thread ]</a>
              <a href="subject.html#128">[ subject ]</a>
              <a href="author.html#128">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/hatari-devel">More information about the hatari-devel
mailing list</a><br>
</body></html>
